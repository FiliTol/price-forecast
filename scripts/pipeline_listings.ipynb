{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:10.681121Z",
     "start_time": "2024-07-30T14:38:08.831417Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from pandas import Timestamp\n",
    "\n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import geodesic\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import re\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.001081Z",
     "start_time": "2024-07-30T14:38:10.685802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_listings = pd.read_csv(\"../data/2023dic/d_listings.csv\")\n",
    "#df_listings = df_listings[['id', 'neighborhood_overview', 'host_id', 'host_since', 'host_location', 'host_about',\n",
    "#                           'host_response_time', 'host_response_rate', 'host_acceptance_rate', 'host_is_superhost',\n",
    "#                           'host_listings_count', 'host_total_listings_count', 'host_verifications',\n",
    "#                           'host_has_profile_pic', 'host_identity_verified', 'neighbourhood_cleansed',\n",
    "#                           'latitude', 'longitude', 'room_type',\n",
    "#                           'accommodates', 'bathrooms_text', 'beds', 'price',\n",
    "#                           'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'has_availability', 'availability_30',\n",
    "#                           'availability_60', 'availability_90', 'availability_365', 'number_of_reviews', 'first_review',\n",
    "#                           'last_review', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness',\n",
    "#                           'review_scores_checkin', 'review_scores_communication', 'review_scores_location',\n",
    "#                           'review_scores_value', 'calculated_host_listings_count',\n",
    "#                           'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms',\n",
    "#                           'calculated_host_listings_count_shared_rooms', 'reviews_per_month']]"
   ],
   "id": "6cf180bc5b7ac523",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.035013Z",
     "start_time": "2024-07-30T14:38:11.015616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_listings.drop(labels=[\"listing_url\", \"name\", \"scrape_id\", \"last_scraped\", \"source\", \"description\", \"picture_url\", \"host_url\",\n",
    "                         \"host_name\", \"host_thumbnail_url\", \"host_picture_url\", \"host_neighbourhood\", \"neighbourhood\",\n",
    "                         \"neighbourhood_group_cleansed\", \"property_type\", \"amenities\", \"minimum_minimum_nights\",\n",
    "                         \"maximum_minimum_nights\", \"minimum_maximum_nights\", \"maximum_maximum_nights\", \"minimum_nights_avg_ntm\",\n",
    "                         \"maximum_nights_avg_ntm\", \"has_availability\", \"availability_30\", \"availability_60\", \"availability_90\",\n",
    "                         \"availability_365\", \"calendar_updated\", \"calendar_last_scraped\", \"number_of_reviews_ltm\",\n",
    "                         \"number_of_reviews_l30d\", \"license\", \"instant_bookable\"],\n",
    "                 axis=1,\n",
    "                 inplace=True)"
   ],
   "id": "d7b761af79c6b9f4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.057804Z",
     "start_time": "2024-07-30T14:38:11.040733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Drop rows with NaN in target \n",
    "#df_listings = df_listings.loc[df_listings['price'].notnull(), :]\n",
    "#df_listings.price.isnull().sum()"
   ],
   "id": "3f9f153a37911bc7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#X = df_listings.drop([\"price\"], axis=1, inplace=False)\n",
    "#y = df_listings[\"price\"]"
   ],
   "id": "91ca6cb5d048b822",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=874631)",
   "id": "a716932ae498c46",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### Feature engineering\n",
    "#- `first_review` to `last_review` as date span\n",
    "#- `host_listings_count` as a % of `host_total_listings_count`\n",
    "#- Manage `neighbourhoods_cleansed` as a OHE of most frequent categories\n",
    "#- Distance between host home and listing location\n",
    "#- Distance between listing and relevant locations in town\n",
    "#- `host_since` encoded as *days of activity until period end (end of dataset scraping)*\n",
    "#- Sentiment of `neighborhood_overview` (investigate best sentiment technique for descriptions of appartments)\n",
    "#- Sentiment of `host_about` (investigate best sentiment technique for description of people)\n",
    "#- `host_id` and `id` as categorial\n",
    "#- `host_response_time` as ordinal variable\n",
    "#- string manipulation for `host_response_rate` and `host_acceptance_rate`\n",
    "#- `host_is_superhost` as binary categorial\n",
    "#- `host_verifications` as encoded in previous script\n",
    "#- `host_has_profile_pic` as binary\n",
    "#- `host_identity_verified` as binary\n",
    "#- keep `room_type` instead of `property_type` and make `room_type` a categorial with OHE\n",
    "#- `accomodates` used with `baths`, `beds` to compute the rate of beds and bathrooms for every person\n",
    "#- `price` with string manipulation\n",
    "#- `minimum_nighs_avg_ntm` as float\n",
    "#- `maximum_nights_avg_ntm` as float\n",
    "#- `has_availability` as binary\n",
    "#- all the `has_availability_NUMBER` as a % of the NUMBER of the feature\n",
    "#- `number_of_reviews` as an integer\n",
    "#- `review_scores_rating` as float\n",
    "#- all the reviews scores as float\n",
    "#- remove `calculated_host_listings_count` and keep the other three BUT **set them as % of the total host listings**\n",
    "#- `reviews_per_month` as float\n",
    "#- `longitude` and `latitude` standardization (because the values are both negatives and positives)"
   ],
   "id": "a72b15ace5d81379",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Transform feature datatypes\n",
    "\n",
    "In this section we execute the feature engineering without dealing with null values.\n",
    "We do it because once the types are cleaned, we want to plot a bit the data and explore it to see what is going on\n",
    "with NAs, frequency distribution, numeric distributions etc.\n",
    "In order to do so, we need to:\n",
    "1. Generalise the pipeline, because we would like to apply this script also to other similar dataset\n",
    "2. Return exceptions for NAs, to carry them on to the data exploration section\n",
    "\n",
    "> ***NOTE*** that the `feature-engine` library enables us to split the dataset into train and test just after the data type and feature engineering. This because the library contains some functions for [preprocessing](https://feature-engine.trainindata.com/en/latest/user_guide/preprocessing/index.html) that can deal with removed rows and features afterwards\n",
    "\n",
    "- [Useful library for feature engineering](https://feature-engine.trainindata.com/en/latest/quickstart/index.html)"
   ],
   "id": "d7e6ae9af4aec729"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Split features into groups based on the data type\n",
    "\n",
    "- Split features for data types (***remember to insert the case where the columns with more than 50% NaN are not included in the splitting at all***)\n",
    "    - Then the pipeline is build to transform the data types\n",
    "    - Based on the previous splitting, apply Imputation methods to all the features. This is done because we don't know if other datasets will have the same null values ripartition\n",
    "    - At this point we need to **drop** the columns not included in the splitting of data types. This because the columns not included will be the ones with a lot of NAs from the start (more than 50%)\n",
    "\n",
    "> *Eventually we could compare the result of this approach with the result of a parallel approach whereby no columns are dropped and the NaNs are all Imputed. Then see how the two models perform*"
   ],
   "id": "f8cc7355c02b8ee7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## To decide if will be included or not in the pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def drop_features_with_many_nan(x: pd.DataFrame) -> pd.DataFrame:\n",
    "    nulls_summary = pd.DataFrame(df_listings.isnull().sum())\n",
    "    more_than_null_features = nulls_summary.loc[nulls_summary.iloc[:, 0] > df_listings.shape[0]*0.5, :].index.tolist()\n",
    "    return x.drop(more_than_null_features, axis=1)\n",
    "\n",
    "fun_tr_drop_features_with_many_nan = FunctionTransformer(drop_features_with_many_nan)"
   ],
   "id": "c5978ab20ef7796",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define groups for data transformation",
   "id": "4619392d43c4fa28"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The following class serves as definition of some general functions to be used for geographic handling",
   "id": "3aaa3fcd554dd608"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.154931Z",
     "start_time": "2024-07-30T14:38:11.124739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "strategic_locations_geo = {\"Aereoporto Marco Polo\": [45.50354, 12.34258],\n",
    "                       \"Piazza Erminio Ferretto\": [45.49479, 12.24251],\n",
    "                       \"Piazzale Roma\": [45.43801, 12.31885],\n",
    "                       \"Ponte di Rialto\": [45.43805, 12.33593],\n",
    "                       \"Piazza San Marco\": [45.434, 12.338]\n",
    "                       }\n",
    "\n",
    "\n",
    "class GeoDataHandler:\n",
    "    def __init__(self, user_agent: str = \"GeoDataHandler\"):\n",
    "        \"\"\"\n",
    "        Initializes the GeoDataHandler with a user agent for Nominatim.\n",
    "        :param user_agent: A string representing the user agent for Nominatim.\n",
    "        \"\"\"\n",
    "        self.geolocator = Nominatim(user_agent=user_agent)\n",
    "        self.geocode = RateLimiter(self.geolocator.geocode, min_delay_seconds=1.1)\n",
    "    \n",
    "    def retrieve_host_location(self, df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        From a dataset of listings, extracts the list of unique host locations\n",
    "        and retrieve latitude and longitude of every location.\n",
    "        :param df: pandas DataFrame of listings.\n",
    "        :return: dict of locations: [latitude, longitude]\n",
    "        \"\"\"\n",
    "        location_geo = {}\n",
    "        try:\n",
    "            for location in df['host_location'].unique().tolist():\n",
    "                host_location = self.geocode(location)\n",
    "                if host_location:\n",
    "                    location_geo[location] = (host_location.latitude, host_location.longitude)\n",
    "                else:\n",
    "                    location_geo[location] = (None, None)\n",
    "            return location_geo\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "    def export_to_json(self, dict_object: dict, path: str) -> None:\n",
    "        \"\"\"\n",
    "        Given a dict with host locations, saves it to a custom path.\n",
    "        :param dict_object: dictionary to be saved as JSON.\n",
    "        :param path: str with the path where to save JSON.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(path, 'w') as f:\n",
    "                json.dump(dict_object, f)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while exporting to JSON: {e}\")\n",
    "\n",
    "    def import_from_json(self, path: str) -> dict:\n",
    "        \"\"\"\n",
    "        Import host location from saved JSON.\n",
    "        :param path: path where the JSON is saved.\n",
    "        :return: JSON in dictionary form.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                dict_object = json.load(f)\n",
    "            return dict_object\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while importing from JSON: {e}\")\n",
    "            return None\n"
   ],
   "id": "26bfd4171739716f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.271655Z",
     "start_time": "2024-07-30T14:38:11.165690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "handler = GeoDataHandler()\n",
    "#locations = handler.retrieve_host_location(df_listings)\n",
    "#handler.export_to_json(locations, \"../data/2023dic/host_locations.json\")\n",
    "locations = handler.import_from_json(\"../data/2023dic/host_locations.json\")\n",
    "\n",
    "strategic_locations_geo = {\"Aereoporto Marco Polo\": [45.50354, 12.34258],\n",
    "                       \"Piazza Erminio Ferretto\": [45.49479, 12.24251],\n",
    "                       \"Piazzale Roma\": [45.43801, 12.31885],\n",
    "                       \"Ponte di Rialto\": [45.43805, 12.33593],\n",
    "                       \"Piazza San Marco\": [45.434, 12.338]\n",
    "                       }\n",
    "#handler.export_to_json(strategic_locations_geo, \"../data/strategic_locations.json\")\n",
    "strategic_locations = handler.import_from_json(\"../data/strategic_locations.json\")"
   ],
   "id": "3a3fd1ef73534c2",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Geographical Features",
   "id": "755900984221522c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.290239Z",
     "start_time": "2024-07-30T14:38:11.274409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_listings.dtypes\n",
    "#df_listings"
   ],
   "id": "a2aec621015ddfa3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                int64\n",
       "neighborhood_overview                            object\n",
       "host_id                                           int64\n",
       "host_since                                       object\n",
       "host_location                                    object\n",
       "host_about                                       object\n",
       "host_response_time                               object\n",
       "host_response_rate                               object\n",
       "host_acceptance_rate                             object\n",
       "host_is_superhost                                object\n",
       "host_listings_count                               int64\n",
       "host_total_listings_count                         int64\n",
       "host_verifications                               object\n",
       "host_has_profile_pic                             object\n",
       "host_identity_verified                           object\n",
       "neighbourhood_cleansed                           object\n",
       "latitude                                        float64\n",
       "longitude                                       float64\n",
       "room_type                                        object\n",
       "accommodates                                      int64\n",
       "bathrooms                                       float64\n",
       "bathrooms_text                                   object\n",
       "bedrooms                                        float64\n",
       "beds                                            float64\n",
       "price                                            object\n",
       "minimum_nights                                    int64\n",
       "maximum_nights                                    int64\n",
       "number_of_reviews                                 int64\n",
       "first_review                                     object\n",
       "last_review                                      object\n",
       "review_scores_rating                            float64\n",
       "review_scores_accuracy                          float64\n",
       "review_scores_cleanliness                       float64\n",
       "review_scores_checkin                           float64\n",
       "review_scores_communication                     float64\n",
       "review_scores_location                          float64\n",
       "review_scores_value                             float64\n",
       "calculated_host_listings_count                    int64\n",
       "calculated_host_listings_count_entire_homes       int64\n",
       "calculated_host_listings_count_private_rooms      int64\n",
       "calculated_host_listings_count_shared_rooms       int64\n",
       "reviews_per_month                               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.299002Z",
     "start_time": "2024-07-30T14:38:11.293596Z"
    }
   },
   "cell_type": "code",
   "source": "geo_features = [\"host_location\"] # + strategic_locations",
   "id": "caf1d6e4ad1b639",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.330965Z",
     "start_time": "2024-07-30T14:38:11.302380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GeographicTransformer(BaseEstimator, TransformerMixin):\n",
    "    # https://datascience.stackexchange.com/questions/117200/creating-new-features-as-linear-combination-of-others-as-part-of-a-scikit-learn\n",
    "    # https://www.andrewvillazon.com/custom-scikit-learn-transformers/\n",
    "    def __init__(self, locations: dict = locations, column: str =\"host_location\"):\n",
    "        \n",
    "        self.column = column\n",
    "        self.locations = locations\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame, y=None):\n",
    "        if self.column == \"host_location\":\n",
    "            X = self.transform_to_coordinates(X, self.locations)\n",
    "            X[self.column] = X.apply(lambda row: self.geodesic_distancer(row, from_loc=\"host_location\"), axis=1)\n",
    "            return X\n",
    "        else:\n",
    "            X = self.create_strategic_locations_features(X)\n",
    "            X = self.apply_location_to_feature(X)\n",
    "            X = self.apply_distancer_to_strategic_locations(X)\n",
    "            return X\n",
    "    \n",
    "    def transform_to_coordinates(self, X, locations: dict):\n",
    "        \"\"\"\n",
    "        Given an entry and a dictionary, returns the latitude, longitude for\n",
    "        the entry that are saved in the dictionary\n",
    "        :param entry: entry (from dataframe)\n",
    "        :param locations: dict of locations:[latitude, longitude]\n",
    "        :return: [latitude, longitude]\n",
    "        \"\"\"\n",
    "        try:\n",
    "            X[self.column] = X[self.column].apply(lambda x: locations.get(x))\n",
    "            return X\n",
    "        except:\n",
    "            return X\n",
    "        \n",
    "    def geodesic_distancer(self, row, from_loc: str):\n",
    "        try:\n",
    "            coords_1 = (row[from_loc][0], row[from_loc][1])\n",
    "            coords_2 = (row[\"latitude\"], row[\"longitude\"])\n",
    "            return geodesic(coords_1, coords_2).km\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_strategic_locations_features(X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X[\"airport_distance_km\"] = None\n",
    "        X[\"ferretto_square_distance_km\"] = None\n",
    "        X[\"roma_square_distance_km\"] = None\n",
    "        X[\"rialto_bridge_distance_km\"] = None\n",
    "        X[\"san_marco_square_distance_km\"] = None\n",
    "        return X\n",
    "    \n",
    "    def apply_location_to_feature(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X[\"airport_distance_km\"] = X[\"airport_distance_km\"].apply(lambda x: self.locations[\"Aereoporto Marco Polo\"])\n",
    "        X[\"ferretto_square_distance_km\"] = X[\"ferretto_square_distance_km\"].apply(lambda x: self.locations[\"Piazza Erminio Ferretto\"])\n",
    "        X[\"roma_square_distance_km\"] = X[\"roma_square_distance_km\"].apply(lambda x: self.locations[\"Piazzale Roma\"])\n",
    "        X[\"rialto_bridge_distance_km\"] = X[\"rialto_bridge_distance_km\"].apply(lambda x: self.locations[\"Ponte di Rialto\"])\n",
    "        X[\"san_marco_square_distance_km\"] = X[\"san_marco_square_distance_km\"].apply(lambda x: self.locations[\"Piazza San Marco\"])\n",
    "        return X\n",
    "    \n",
    "    def apply_distancer_to_strategic_locations(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X['airport_distance_km'] = X.apply(lambda row: self.geodesic_distancer(row=row, from_loc=\"airport_distance_km\"), axis=1)\n",
    "        X['ferretto_square_distance_km'] = X.apply(lambda row: self.geodesic_distancer(row=row, from_loc=\"ferretto_square_distance_km\"), axis=1)\n",
    "        X['roma_square_distance_km'] = X.apply(lambda row: self.geodesic_distancer(row=row, from_loc=\"roma_square_distance_km\"), axis=1)\n",
    "        X['rialto_bridge_distance_km'] = X.apply(lambda row: self.geodesic_distancer(row=row, from_loc=\"rialto_bridge_distance_km\"), axis=1)\n",
    "        X['san_marco_square_distance_km'] = X.apply(lambda row: self.geodesic_distancer(row=row, from_loc=\"san_marco_square_distance_km\"), axis=1)\n",
    "        return X\n",
    "\n",
    "        "
   ],
   "id": "f6f9b580f4501783",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.344790Z",
     "start_time": "2024-07-30T14:38:11.334530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "geographic_pipeline = Pipeline(steps=[\n",
    "    ('Host location transformer', GeographicTransformer(column=\"host_location\", locations=locations)),\n",
    "    (\"Strategic locations distance\", GeographicTransformer(column=\"strategic_locations\", locations=strategic_locations))\n",
    "])"
   ],
   "id": "bc8f2c1aeb6c4e9c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### String features",
   "id": "75cdfcb5a9dfbcdf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.355398Z",
     "start_time": "2024-07-30T14:38:11.348116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "string_features = [\"neighborhood_overview\",\n",
    "                   \"host_about\"]"
   ],
   "id": "3f2f6b7237a34b54",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Procedure for the string features in order to extract encoded features from text:\n",
    "- use the tf-idf in order to gain a vector of encoded normalized word scores\n",
    "- Use the vector as a feature in the dataset\n",
    "- the vector does not need other normalization aspects"
   ],
   "id": "45fa1ed0d4d0c623"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.370629Z",
     "start_time": "2024-07-30T14:38:11.358954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def trasform_nan_unicode(text_series):\n",
    "    return text_series.fillna(\"\").astype('U')\n",
    "\n",
    "text_encoding_pipeline = Pipeline(steps=[\n",
    "    (\"text preprocessing\", FunctionTransformer(trasform_nan_unicode, validate=False)),\n",
    "    (\"tf-idf vectorizer\", TfidfVectorizer(encoding='utf-8',\n",
    "                                          decode_error='ignore',\n",
    "                                          strip_accents='unicode',\n",
    "                                          lowercase=True,\n",
    "                                          analyzer='word',\n",
    "                                          max_df=0.8,\n",
    "                                          use_idf=True,\n",
    "                                          smooth_idf=True)\n",
    "     )\n",
    "])"
   ],
   "id": "b70d1a23bcf37aa7",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ID features",
   "id": "dfb622d4eee327c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.383184Z",
     "start_time": "2024-07-30T14:38:11.374248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "id_feature = [\"id\",\n",
    "              \"host_id\"]"
   ],
   "id": "292ddfeec544d581",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.395560Z",
     "start_time": "2024-07-30T14:38:11.385765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def id_to_string(id_object) -> str:\n",
    "    return id_object.astype(str)"
   ],
   "id": "f69d983a4475c8a7",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.406223Z",
     "start_time": "2024-07-30T14:38:11.399478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "id_pipeline = Pipeline(steps=[\n",
    "    (\"From ID to string\", FunctionTransformer(id_to_string))\n",
    "])"
   ],
   "id": "5b911b4a11b7cb8",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Rates features",
   "id": "c8a69e0ca2efac17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.416457Z",
     "start_time": "2024-07-30T14:38:11.408568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rate_feature = [\"host_response_rate\",\n",
    "                \"host_acceptance_rate\"]"
   ],
   "id": "222bdedf65f1d7ba",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.428059Z",
     "start_time": "2024-07-30T14:38:11.419711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def from_string_to_rate(rate_string: str) -> float:\n",
    "    return rate_string.str.rstrip('%').astype(float)\n",
    "    "
   ],
   "id": "82fb53c30febd6af",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.439091Z",
     "start_time": "2024-07-30T14:38:11.430741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rates_pipeline = Pipeline(steps=[\n",
    "    (\"Transform response rate\", FunctionTransformer(from_string_to_rate))\n",
    "])"
   ],
   "id": "7d85c87b7799146",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Time features",
   "id": "94ef10fa86378680"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.450462Z",
     "start_time": "2024-07-30T14:38:11.442572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "time_feature = [\"host_since\",\n",
    "                \"first_review\",\n",
    "                \"last_review\"]"
   ],
   "id": "561c1cfef5706295",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.462531Z",
     "start_time": "2024-07-30T14:38:11.453563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def trasform_to_datetime(text_date: str) -> pd.Timestamp | pd.Timestamp:\n",
    "    return pd.to_datetime(text_date)"
   ],
   "id": "2064243695abe512",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.472649Z",
     "start_time": "2024-07-30T14:38:11.465780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "timestamp_pipeline = Pipeline(steps=[\n",
    "    (\"Trasform to timestamp\", FunctionTransformer(trasform_to_datetime))\n",
    "])"
   ],
   "id": "72fcd46543902930",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " ## Categorial features\n",
    " \n",
    "### Neighbourhoods features"
   ],
   "id": "6ad49c40c607c967"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.495213Z",
     "start_time": "2024-07-30T14:38:11.476544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "neighbourhood_feature = [\"neighbourhood_cleansed\"]\n",
    "\n",
    "new_neighbourhoods_levels = {'Cannaregio': 'Centro Storico',\n",
    "                             'San Marco':'Centro Storico',\n",
    "                             'Isola San Giorgio': 'Centro Storico',\n",
    "                             'San Polo':'Centro Storico',\n",
    "                             'Castello': 'Centro Storico',\n",
    "                             \"Sant'Elena\": 'Centro Storico',\n",
    "                             'Dorsoduro': 'Centro Storico',\n",
    "                             'Sacca Fisola': 'Centro Storico',\n",
    "                             'Giudecca': 'Centro Storico',\n",
    "                             'Tronchetto': 'Centro Storico',\n",
    "                             'Santa Croce': 'Centro Storico',\n",
    "                             \"Ca' Emiliani\": 'Terraferma',\n",
    "                             'Marghera Zona Industriale': 'Terraferma',\n",
    "                             'Marghera Catene': 'Terraferma',\n",
    "                             'Marghera': 'Terraferma',\n",
    "                             \"Ca' Sabbioni\":'Terraferma',\n",
    "                             'Giustizia': 'Terraferma',\n",
    "                             'San Lorenzo XXV Aprile': 'Terraferma',\n",
    "                             'Bissuola': 'Terraferma',\n",
    "                             'Cipressina': 'Terraferma',\n",
    "                             'Zona Commerciale via Torino': 'Terraferma',\n",
    "                             'Carpenedo': 'Terraferma',\n",
    "                             'Villabona': 'Terraferma',\n",
    "                             'Santa Barbara': 'Terraferma',\n",
    "                             'Altobello': 'Terraferma',\n",
    "                             'Piave 1860': 'Terraferma',\n",
    "                             'La Favorita': 'Terraferma',\n",
    "                             'Villaggio Sartori': 'Terraferma',\n",
    "                             'Villaggio San Marco': 'Terraferma',\n",
    "                             'Gazzera': 'Terraferma',\n",
    "                             'Asseggiano': 'Terraferma',\n",
    "                             \"Pra' Secco\": 'Terraferma',\n",
    "                             'Gatta - Bondu?': 'Terraferma',\n",
    "                             'Quartiere Pertini': 'Terraferma',\n",
    "                             'Campalto CEP': 'Terraferma',\n",
    "                             'Mestre': 'Terraferma',\n",
    "                             \"Scaramuzza\": \"Terraferma\",\n",
    "                             'Alberoni': 'Isole',\n",
    "                             'Malamocco': 'Isole',\n",
    "                             'Lido': 'Isole',\n",
    "                             \"Sant'Erasmo\": 'Isole',\n",
    "                             'Burano': 'Isole',\n",
    "                             'San Pietro in Volta': 'Isole',\n",
    "                             'Mazzorbo': 'Isole',\n",
    "                             'Pellestrina': 'Isole',\n",
    "                             'Murano': 'Isole',\n",
    "                             'Torcello': 'Isole',\n",
    "                             'Favaro': 'Terraferma',\n",
    "                             'Case Dosa': 'Terraferma',\n",
    "                             'Marocco Terraglio': 'Terraferma',\n",
    "                             'Campalto Gobbi': 'Terraferma',\n",
    "                             'Malcontenta': 'Terraferma',\n",
    "                             'Zelarino': 'Terraferma',\n",
    "                             'Chirignago': 'Terraferma',\n",
    "                             'Campalto Bagaron': 'Terraferma',\n",
    "                             'Dese': 'Terraferma',\n",
    "                             'Torre Antica': 'Terraferma',\n",
    "                             'Aeroporto': 'Terraferma',\n",
    "                             'Tessera':'Terraferma',\n",
    "                             'Campalto': 'Terraferma',\n",
    "                             'other city': 'Terraferma'}\n",
    "\n",
    "#handler.export_to_json(new_neighbourhoods_levels, \"../data/2023dic/neighbourhoods_levels.json\")\n",
    "neighbourhood_levels = handler.import_from_json(\"../data/2023dic/neighbourhoods_levels.json\")"
   ],
   "id": "c4b63f68bce30510",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.510880Z",
     "start_time": "2024-07-30T14:38:11.498865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NeighborhoodMapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, mapping):\n",
    "        self.mapping = mapping\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        return X.replace(self.mapping)\n",
    "\n",
    "neighbourhood_pipeline = Pipeline(steps=[\n",
    "    ('Neighbourhood Mapper', NeighborhoodMapper(mapping=neighbourhood_levels))\n",
    "])"
   ],
   "id": "2ae79a3a92827013",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Verifications Feature",
   "id": "41d97ee3c79387a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.535599Z",
     "start_time": "2024-07-30T14:38:11.522073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def new_features_for_verifications(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['email_verification'] = 'f'\n",
    "    df['phone_verification'] = 'f'\n",
    "    df['work_email_verification'] = 'f'\n",
    "    return df\n",
    "\n",
    "def allocate_verifications_to_variables(row):\n",
    "    if \"email\" in row[\"host_verifications\"]:\n",
    "        row[\"email_verification\"] = 't'\n",
    "    if \"phone\" in row[\"host_verifications\"]:\n",
    "        row[\"phone_verification\"] = 't'\n",
    "    if \"work_email\" in row[\"host_verifications\"]:\n",
    "        row[\"work_email_verification\"] = 't'\n",
    "    return row\n",
    "\n",
    "def apply_on_every_row(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.apply(allocate_verifications_to_variables, axis=1)\n",
    "\n",
    "verifications_pipeline = Pipeline(steps=[\n",
    "    ('Create features', FunctionTransformer(new_features_for_verifications)),\n",
    "    ('Allocate verifications', FunctionTransformer(apply_on_every_row))\n",
    "])\n"
   ],
   "id": "edb1645163407202",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Bathrooms text feature",
   "id": "edda8d7f63f2dbd5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.555235Z",
     "start_time": "2024-07-30T14:38:11.538564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bathroom_text_feature = [\"bathrooms_text\"]\n",
    "\n",
    "remap_baths = {\n",
    "    'baths': 'single',\n",
    "    'bath': 'single',\n",
    "    'private bath': 'private',\n",
    "    'shared bath': 'shared',\n",
    "    'shared baths': 'shared',\n",
    "    'Shared half-bath': 'shared',\n",
    "    '. baths': 'single',\n",
    "    '. shared baths': 'shared',\n",
    "    'Half-bath': 'single',\n",
    "    'Private half-bath': 'private'\n",
    "}\n",
    "\n",
    "handler.export_to_json(remap_baths, '../data/2023dic/baths.json')\n",
    "remap_baths = handler.import_from_json('../data/2023dic/baths.json')\n",
    "\n",
    "class BathroomsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, mapping):\n",
    "        self.mapping = mapping\n",
    "\n",
    "    def extract_digits(self, text):\n",
    "        if pd.isna(text):\n",
    "            return '0'\n",
    "        if \"half\" in text.lower():\n",
    "            return '0.5'\n",
    "        digits = re.findall(r'\\d+\\.\\d+|\\d+', str(text))\n",
    "        return ''.join(digits) if digits else '0'\n",
    "\n",
    "    def remove_digits(self, text):\n",
    "        if pd.isna(text):\n",
    "            return ''\n",
    "        return re.sub(r'\\d', '', str(text)).strip()\n",
    "\n",
    "    def create_baths_column(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df['bathrooms'] = df['bathrooms_text'].apply(self.extract_digits)\n",
    "        df['bathrooms'] = df['bathrooms'].astype(float)\n",
    "        return df\n",
    "\n",
    "    def clean_bathrooms_text(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df['bathrooms_text'] = df['bathrooms_text'].apply(self.remove_digits)\n",
    "        return df\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        X = self.create_baths_column(X)\n",
    "        X = self.clean_bathrooms_text(X)\n",
    "        return X.replace(self.mapping) \n",
    "    \n",
    "bathrooms_pipeline = Pipeline(steps=[\n",
    "    ('Remap bathrooms text', BathroomsTransformer(remap_baths))\n",
    "])    "
   ],
   "id": "2ecd8f327d4daedb",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Price feature",
   "id": "542bf82a72ee2d43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:11.566886Z",
     "start_time": "2024-07-30T14:38:11.557614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "price_feature = ['price']\n",
    "\n",
    "def remove_symbols(text):\n",
    "    try:\n",
    "        cleaned_text = re.sub(r'[$,]', '', text)\n",
    "        return cleaned_text.strip()\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def remove_dollar_sign(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['price'] = df['price'].apply(remove_symbols).astype(float)\n",
    "    return df\n",
    "    \n",
    "price_pipeline = Pipeline(steps=[\n",
    "    (\"Trim price feature\", FunctionTransformer(remove_dollar_sign))\n",
    "])\n",
    "    "
   ],
   "id": "b2eb5e6b3365797b",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Aggregate visualization dataset",
   "id": "1d8ad1cb51c8d253"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:54:29.780562Z",
     "start_time": "2024-07-30T14:54:29.772240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn import set_config\n",
    "set_config(transform_output = \"pandas\")\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"Geographic\", geographic_pipeline, df_listings),\n",
    "    (\"Text encoding\", text_encoding_pipeline, string_features),\n",
    "    (\"Id\", id_pipeline, id_feature),\n",
    "    (\"Rates\", rates_pipeline, rate_feature),\n",
    "    (\"Timestamp\", timestamp_pipeline, time_feature),\n",
    "    (\"Neighbourhood\", neighbourhood_pipeline, neighbourhood_feature),\n",
    "    (\"Verifications\", verifications_pipeline, df_listings),\n",
    "    (\"Bathrooms\", bathrooms_pipeline, bathroom_text_feature),\n",
    "    (\"Price\", price_pipeline, price_feature)\n",
    "],\n",
    "    remainder=\"passthrough\",\n",
    "    n_jobs=-1\n",
    ")"
   ],
   "id": "772205159d1e3b76",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:54:32.103358Z",
     "start_time": "2024-07-30T14:54:31.239554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.utils import estimator_html_repr\n",
    "with open('visualization_pipeline.html', 'w') as f:  \n",
    "    f.write(estimator_html_repr(preprocessor))\n"
   ],
   "id": "b3f58f3e1a70c552",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:57:10.739875Z",
     "start_time": "2024-07-30T14:57:10.599600Z"
    }
   },
   "cell_type": "code",
   "source": "preprocessor.fit_transform(df_listings)",
   "id": "61aff34319152efb",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No valid specification of the columns. Only a scalar, list or slice of all integers or all strings, or boolean mask is allowed",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[47], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mpreprocessor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_listings\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/repositories/price-forecast/venv/lib/python3.10/site-packages/sklearn/utils/_set_output.py:313\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 313\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    315\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    316\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    317\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    318\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    319\u001B[0m         )\n",
      "File \u001B[0;32m~/repositories/price-forecast/venv/lib/python3.10/site-packages/sklearn/base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1471\u001B[0m     )\n\u001B[1;32m   1472\u001B[0m ):\n\u001B[0;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/repositories/price-forecast/venv/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:968\u001B[0m, in \u001B[0;36mColumnTransformer.fit_transform\u001B[0;34m(self, X, y, **params)\u001B[0m\n\u001B[1;32m    965\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_transformers()\n\u001B[1;32m    966\u001B[0m n_samples \u001B[38;5;241m=\u001B[39m _num_samples(X)\n\u001B[0;32m--> 968\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_column_callables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    969\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_remainder(X)\n\u001B[1;32m    971\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _routing_enabled():\n",
      "File \u001B[0;32m~/repositories/price-forecast/venv/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:536\u001B[0m, in \u001B[0;36mColumnTransformer._validate_column_callables\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    534\u001B[0m         columns \u001B[38;5;241m=\u001B[39m columns(X)\n\u001B[1;32m    535\u001B[0m     all_columns\u001B[38;5;241m.\u001B[39mappend(columns)\n\u001B[0;32m--> 536\u001B[0m     transformer_to_input_indices[name] \u001B[38;5;241m=\u001B[39m \u001B[43m_get_column_indices\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    538\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_columns \u001B[38;5;241m=\u001B[39m all_columns\n\u001B[1;32m    539\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transformer_to_input_indices \u001B[38;5;241m=\u001B[39m transformer_to_input_indices\n",
      "File \u001B[0;32m~/repositories/price-forecast/venv/lib/python3.10/site-packages/sklearn/utils/_indexing.py:326\u001B[0m, in \u001B[0;36m_get_column_indices\u001B[0;34m(X, key)\u001B[0m\n\u001B[1;32m    320\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_column_indices\u001B[39m(X, key):\n\u001B[1;32m    321\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get feature column indices for input data X and key.\u001B[39;00m\n\u001B[1;32m    322\u001B[0m \n\u001B[1;32m    323\u001B[0m \u001B[38;5;124;03m    For accepted values of `key`, see the docstring of\u001B[39;00m\n\u001B[1;32m    324\u001B[0m \u001B[38;5;124;03m    :func:`_safe_indexing`.\u001B[39;00m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 326\u001B[0m     key_dtype \u001B[38;5;241m=\u001B[39m \u001B[43m_determine_key_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    327\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _use_interchange_protocol(X):\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _get_column_indices_interchange(X\u001B[38;5;241m.\u001B[39m__dataframe__(), key, key_dtype)\n",
      "File \u001B[0;32m~/repositories/price-forecast/venv/lib/python3.10/site-packages/sklearn/utils/_indexing.py:173\u001B[0m, in \u001B[0;36m_determine_key_type\u001B[0;34m(key, accept_slice)\u001B[0m\n\u001B[1;32m    171\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[1;32m    172\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(err_msg)\n\u001B[0;32m--> 173\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(err_msg)\n",
      "\u001B[0;31mValueError\u001B[0m: No valid specification of the columns. Only a scalar, list or slice of all integers or all strings, or boolean mask is allowed"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pipeline for visualization ENDED",
   "id": "60498a2684c269c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Numerical features",
   "id": "e9e054fc6211afeb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:38:13.412604Z",
     "start_time": "2024-07-30T14:38:13.411729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_features = [\"host_listings_count\", \"host_total_listings_count\", \"accommodates\", \"bathrooms\", \"bedrooms\", \"beds\",\n",
    "                \"minimum_nights\", \"maximum_nights\", \"number_of_reviews\", \"review_scores_rating\", \"review_scores_accuracy\",\n",
    "                \"review_scores_cleanliness\", \"review_scores_checkin\", \"review_scores_communication\",\n",
    "                \"review_scores_location\", \"review_scores_value\", \"calculated_host_listings_count\",\n",
    "                \"calculated_host_listings_count_entire_homes\", \"calculated_host_listings_count_private_rooms\",\n",
    "                \"calculated_host_listings_count_shared_rooms\", \"reviews_per_month\"\n",
    "                ]"
   ],
   "id": "4a5eec912159bebd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Add and manipulate features",
   "id": "79720a1c16896a6a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
