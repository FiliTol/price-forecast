{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-07T16:58:21.294708Z",
     "start_time": "2024-09-07T16:58:18.196690Z"
    }
   },
   "source": [
    "import sys\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from src.tools import JsonHandler, concatenate_listings_datasets, return_cleaned_col_names, preprocess_text\n",
    "from src.class_transformers import (\n",
    "    GeographicTransformer,\n",
    "    BathroomsTransformer,\n",
    "    CreateVerificationsTransformer,\n",
    "    AmenitiesTransformer,\n",
    "    OfflineLocationFinder,\n",
    "    PropertyTypeTransformer,\n",
    "    HostLocationImputer,\n",
    "    ScrapingDateTransformer\n",
    ")\n",
    "from src.function_transformers import (\n",
    "    fun_tr_id_to_string,\n",
    "    fun_tr_from_string_to_rate,\n",
    "    fun_tr_transform_to_datetime,\n",
    "    fun_tr_remove_dollar_sign,\n",
    ")\n",
    "from sklearn.utils import estimator_html_repr\n",
    "from sklearn import set_config\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "pandarallel.initialize()\n",
    "pd.options.display.float_format = \"{:.0f}\".format\n",
    "handler = JsonHandler()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Viz pipeline",
   "id": "5eb760b130fee773"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T16:58:39.741188Z",
     "start_time": "2024-09-07T16:58:21.297145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Importing dataset and other data...\")\n",
    "df_listings = concatenate_listings_datasets()\n",
    "host_locations = handler.import_from_json(\"data/mappings/host_locations.json\")\n",
    "remap_baths = handler.import_from_json(\"data/mappings/baths.json\")\n",
    "print(\"Data imported!\")\n",
    "\n",
    "print(\"Dropping columns and rows with too many NAs...\")\n",
    "df_listings.drop(\n",
    "    [\n",
    "        \"description\",\n",
    "        \"neighborhood_overview\",\n",
    "        \"host_about\",\n",
    "        \"host_neighbourhood\",\n",
    "        \"neighbourhood\",\n",
    "        \"neighbourhood_group_cleansed\",\n",
    "        \"calendar_updated\",\n",
    "        \"license\",\n",
    "        \"listing_url\",\n",
    "        \"scrape_id\",\n",
    "        \"last_scraped\",\n",
    "        \"source\",\n",
    "        \"name\",\n",
    "        \"picture_url\",\n",
    "        \"host_url\",\n",
    "        \"host_name\",\n",
    "        \"host_thumbnail_url\",\n",
    "        \"host_picture_url\",\n",
    "        \"minimum_minimum_nights\",\n",
    "        \"maximum_minimum_nights\",\n",
    "        \"minimum_maximum_nights\",\n",
    "        \"maximum_maximum_nights\",\n",
    "        \"minimum_nights_avg_ntm\",\n",
    "        \"maximum_nights_avg_ntm\",\n",
    "        \"has_availability\",\n",
    "        \"availability_30\",\n",
    "        \"availability_60\",\n",
    "        \"availability_90\",\n",
    "        \"availability_365\",\n",
    "        \"calendar_last_scraped\",\n",
    "        \"number_of_reviews_ltm\",\n",
    "        \"number_of_reviews_l30d\",\n",
    "        \"instant_bookable\",\n",
    "        \"calculated_host_listings_count\",\n",
    "        \"calculated_host_listings_count_entire_homes\",\n",
    "        \"calculated_host_listings_count_private_rooms\",\n",
    "        \"calculated_host_listings_count_shared_rooms\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "df_listings.set_index(\"id\", inplace=True)\n",
    "\n",
    "df_nas_columns = pd.DataFrame(\n",
    "    {\n",
    "        \"NAs\": df_listings.isnull().sum(axis=1),\n",
    "        \"Columns_with_NAs\": df_listings.apply(\n",
    "            lambda x: \", \".join(x.index[x.isnull()]), axis=1\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "more_than_7_missing = df_nas_columns.loc[df_nas_columns[\"NAs\"] > 7, :].index.tolist()\n",
    "df_listings.drop(more_than_7_missing, inplace=True)\n",
    "print(\"Columns and rows dropping completed!\")"
   ],
   "id": "f95470ef5e0043d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing dataset and other data...\n",
      "Data imported!\n",
      "Dropping columns and rows with too many NAs...\n",
      "Columns and rows dropping completed!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T16:58:39.766414Z",
     "start_time": "2024-09-07T16:58:39.746185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "id_feature = [\"host_id\"]\n",
    "rate_feature = [\"host_response_rate\", \"host_acceptance_rate\"]\n",
    "time_feature = [\"host_since\", \"first_review\", \"last_review\"]\n",
    "neighbourhood_feature = [\"neighbourhood_cleansed\"]\n",
    "price_feature = [\"price\"]\n",
    "\n",
    "# Amenities\n",
    "internet_pattern: str = r\"\\b(wifi|internet|ethernet|fibra|connection)\\b\"\n",
    "self_checkin_pattern: str = r\"\\b(self checkin|self check-in|self-checkin)\\b\"\n",
    "host_greeting_pattern: str = r\"\\b(host greeting|host greets you)\\b\"\n",
    "pool_pattern: str = r\"\\b(pool|pool view|shared pool)\\b\"\n",
    "oven_pattern: str = r\"\\b(oven)\\b\"\n",
    "microwave_pattern: str = r\"\\b(microwave|microonde)\\b\"\n",
    "garden_pattern: str = r\"\\b(garden|park|backyard)\\b\"\n",
    "streaming_pattern: str = r\"\\b(netflix|amazon|disney+|chromecast|apple tv|hbo|hbo max)\\b\"\n",
    "gym_pattern: str = r\"\\b(exercise|gym|fitness|private gym in building|shared gym|gym nearby|workout bench)\\b\"\n",
    "elevator_pattern: str = r\"\\b(elevator)\\b\"\n",
    "heating_pattern: str = r\"\\b(heating)\\b\"\n",
    "ac_pattern: str = r\"\\b(central air conditioning|ac|air conditioning)\\b\"\n",
    "safe_pattern: str = r\"\\b(safe|locker|lock|security|guard)\\b\"\n",
    "workspace_pattern: str = r\"\\b(workspace|work)\\b\"\n",
    "freezer_pattern: str = r\"\\b(freezer|refrigerator)\\b\"\n",
    "aid_pattern: str = r\"\\b(first aid kit|aid)\\b\"\n",
    "dishwasher_pattern: str = r\"\\b(dishwasher)\\b\"\n",
    "long_term_stays_pattern: str = r\"\\b(long term stays)\\b\"\n",
    "pets_pattern: str = r\"\\b(pets allowed)\\b\"\n",
    "bathtube_pattern: str = r\"\\b(bathtube)\\b\"\n",
    "bbq_grill_pattern: str = r\"\\b(bbq grill|grill|barbeque|barbeque utensils)\\b\"\n",
    "lake_bay_pattern: str = r\"\\b(lake view|bay view|harbor view|beach view)\\b\"\n",
    "\n",
    "set_amenities_remapper = [\n",
    "    (internet_pattern, \"internet\"),\n",
    "    (self_checkin_pattern, \"self-checkin\"),\n",
    "    (host_greeting_pattern, \"host-greeting\"),\n",
    "    (pool_pattern, \"pool\"),\n",
    "    (oven_pattern, \"oven\"),\n",
    "    (microwave_pattern, \"microwave\"),\n",
    "    (garden_pattern, \"garden\"),\n",
    "    (streaming_pattern, \"streaming\"),\n",
    "    (gym_pattern, \"gym\"),\n",
    "    (elevator_pattern, \"elevator\"),\n",
    "    (heating_pattern, \"heating\"),\n",
    "    (ac_pattern, \"air-conditioning\"),\n",
    "    (workspace_pattern, \"workspace\"),\n",
    "    (freezer_pattern, \"freezer\"),\n",
    "    (aid_pattern, \"first-aid-kit\"),\n",
    "    (dishwasher_pattern, \"dishwasher\"),\n",
    "    (long_term_stays_pattern, \"long-term-stays\"),\n",
    "    (pets_pattern, \"pets-allowed\"),\n",
    "    (bathtube_pattern, \"bathtube\"),\n",
    "    (bbq_grill_pattern, \"bbq-grill\"),\n",
    "    (lake_bay_pattern, \"lake-bay-view\")\n",
    "]\n",
    "\n",
    "# Property type\n",
    "entire_property_pattern = r\"\\b(entire|tiny home)\\b\"\n",
    "private_room_pattern = r\"\\b(private room|room in serviced apartment|room in bed and breakfast|room in hotel|room in resort)\\b\"\n",
    "shared_room_pattern = r\"\\b(shared room|shared)\\b\"\n",
    "other_room_pattern = r\"\\b(entire|tiny home|private room|room in serviced apartment|room in bed and breakfast|room in hotel|room in resort|shared room|shared)\\b\"\n",
    "\n",
    "set_property_type_remapper = [\n",
    "    (entire_property_pattern, \"entire_property\"),\n",
    "    (private_room_pattern, \"private_room\"),\n",
    "    (shared_room_pattern, \"shared_room\"),\n",
    "    (other_room_pattern, \"other\"),\n",
    "]\n",
    "\n",
    "id_pipeline = Pipeline(steps=[(\"From ID to string\", fun_tr_id_to_string)], verbose=True)\n",
    "\n",
    "rates_pipeline = Pipeline(\n",
    "    steps=[(\"Transform response rate\", fun_tr_from_string_to_rate)], verbose=True\n",
    ")\n",
    "\n",
    "timestamp_pipeline = Pipeline(\n",
    "    steps=[(\"Transform to timestamp\", fun_tr_transform_to_datetime)], verbose=True\n",
    ")\n",
    "\n",
    "price_pipeline = Pipeline(\n",
    "    steps=[(\"Trim price feature\", fun_tr_remove_dollar_sign)], verbose=True\n",
    ")\n"
   ],
   "id": "da0900949f0171a5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:08:03.187938Z",
     "start_time": "2024-09-07T16:58:39.769398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply to all dataset (feature engineering using other features)\n",
    "feature_creation_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"Listing Locations\", OfflineLocationFinder()),\n",
    "        (\"Host Locations imputer\", HostLocationImputer()),\n",
    "        (\n",
    "            \"Host location\",\n",
    "            GeographicTransformer(column=\"host_location\", locations=host_locations),\n",
    "        ),\n",
    "        (\"Host verifications\", CreateVerificationsTransformer()),\n",
    "        (\"Bathrooms\", BathroomsTransformer(remap_baths)),\n",
    "        (\n",
    "            \"Amenities\",\n",
    "            AmenitiesTransformer(df=df_listings, remapper=set_amenities_remapper),\n",
    "        ),\n",
    "        (\n",
    "            \"Property type\",\n",
    "            PropertyTypeTransformer(\n",
    "                df=df_listings, remapper=set_property_type_remapper\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    verbose=True,\n",
    ")\n",
    "print(\"Executing Feature Creation Pipeline...\")\n",
    "df_listings = feature_creation_pipeline.fit_transform(df_listings)\n",
    "print(\"Feature Creation Pipeline completed!\")"
   ],
   "id": "6f7880cc870a9768",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Feature Creation Pipeline...\n",
      "[Pipeline] . (step 1 of 7) Processing Listing Locations, total=  36.1s\n",
      "[Pipeline]  (step 2 of 7) Processing Host Locations imputer, total=   5.0s\n",
      "[Pipeline] ..... (step 3 of 7) Processing Host location, total=  27.5s\n",
      "[Pipeline]  (step 4 of 7) Processing Host verifications, total=  14.8s\n",
      "[Pipeline] ......... (step 5 of 7) Processing Bathrooms, total=   1.6s\n",
      "[Pipeline] ......... (step 6 of 7) Processing Amenities, total= 5.1min\n",
      "[Pipeline] ..... (step 7 of 7) Processing Property type, total=   0.2s\n",
      "Feature Creation Pipeline completed!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:12.611502Z",
     "start_time": "2024-09-07T17:08:03.191375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Executing preprocessing on features...\")\n",
    "feature_preprocessor = ColumnTransformer(\n",
    "    remainder=\"passthrough\",\n",
    "    n_jobs=-1,\n",
    "    force_int_remainder_cols=False,\n",
    "    transformers=[\n",
    "        (\"Id\", id_pipeline, id_feature),\n",
    "        (\"Rates\", rates_pipeline, rate_feature),\n",
    "        (\"Price\", price_pipeline, price_feature),\n",
    "        (\"Timestamp\", timestamp_pipeline, time_feature),\n",
    "    ],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "cleaned_df = feature_preprocessor.fit_transform(df_listings)\n",
    "print(\"Preprocessing on features completed!\")\n",
    "cleaned_df.columns = return_cleaned_col_names(cleaned_df.columns)\n",
    "print(\"Cleaned feature names retrieved\")\n",
    "\n",
    "del df_listings"
   ],
   "id": "17e5bc2393f07179",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing preprocessing on features...\n",
      "Preprocessing on features completed!\n",
      "Cleaned feature names retrieved\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:12.620614Z",
     "start_time": "2024-09-07T17:09:12.615174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Description preprocessing\n",
    "#print(\"Preprocessing listings descriptions\")\n",
    "#cleaned_df[\"description\"] = cleaned_df[\"description\"].parallel_apply(preprocess_text)\n",
    "#print(\"Preprocessing listings descriptions ended\")"
   ],
   "id": "981ef8aa4270f1a5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:12.641224Z",
     "start_time": "2024-09-07T17:09:12.624386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#print(\"Descriptions word count computation\")\n",
    "#cleaned_df['description_word_count'] = cleaned_df['description'].parallel_apply(lambda x: len(x.split()))\n",
    "#print(\"Descriptions word count computation ended\")"
   ],
   "id": "263d3ba629cb4dad",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:12.651908Z",
     "start_time": "2024-09-07T17:09:12.644378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#print(\"Description sentitment and polarity computation\")\n",
    "#cleaned_df['description_sentiment_polarity'] = cleaned_df['description'].parallel_apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "#cleaned_df['description_sentiment_subjectivity'] = cleaned_df['description'].parallel_apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "#print(\"Description sentitment and polarity computation ended\")"
   ],
   "id": "6d0e751d6da098d6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:12.662840Z",
     "start_time": "2024-09-07T17:09:12.654892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#n_features_vec = 100\n",
    "#print(f\"Startup Tfid vectorizer with {n_features_vec} features\")\n",
    "#tfidf = TfidfVectorizer(max_features=n_features_vec,\n",
    "#                        max_df=0.95,\n",
    "#                        min_df=0.05,\n",
    "#                        use_idf=True,\n",
    "#                        )\n",
    "#print(\"Creating the Tfid vectorized dataset for description feature\")\n",
    "#tfidf_matrix = tfidf.fit_transform(cleaned_df['description'])\n",
    "#print(\"Creating the Tfid vectorized dataset for description feature ended\")"
   ],
   "id": "3ef406f0fd77d8bc",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:12.673503Z",
     "start_time": "2024-09-07T17:09:12.665699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#print(\"Converting TF-IDF matrix to DataFrame, then concatenating with original DataFrame\")\n",
    "#tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())"
   ],
   "id": "6bae51e332e19437",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:12.686270Z",
     "start_time": "2024-09-07T17:09:12.681742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#cleaned_df = pd.concat([cleaned_df, tfidf_df], axis=1)\n",
    "#print(\"Description preprocessing ended\")"
   ],
   "id": "515eadb85963d730",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tourism data",
   "id": "951a0eb7af4ec3a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:15.569043Z",
     "start_time": "2024-09-07T17:09:12.689663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tourism_city_data = pd.read_excel(\"data/city_data/urb_ctour_page_spreadsheet.xlsx\",\n",
    "                        sheet_name=\"Data\",\n",
    "                        index_col=0,\n",
    "                        )\n",
    "\n",
    "col_names_tourism_data = [i.replace(\" \", \"_\") for i in tourism_city_data.columns.tolist()]\n",
    "\n",
    "rename_tourism_columns = {}\n",
    "loop_index = 0\n",
    "for el in tourism_city_data.columns.tolist():\n",
    "    rename_tourism_columns[el] = col_names_tourism_data[loop_index]\n",
    "    loop_index += 1\n",
    "    \n",
    "tourism_city_data.rename(columns=rename_tourism_columns, inplace=True)"
   ],
   "id": "350693489df01356",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:15.577550Z",
     "start_time": "2024-09-07T17:09:15.571703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rename_cities = {\n",
    "    \"Venezia\": \"ve\",\n",
    "    \"Milano\": \"mi\",\n",
    "    \"Bergamo\": \"bg\",\n",
    "    \"Roma\": \"rm\",\n",
    "    \"Firenze\": \"fi\",\n",
    "    \"Bologna\": \"bo\",\n",
    "    \"Napoli\": \"na\"\n",
    "}"
   ],
   "id": "5210f50ccba1d6e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:15.597064Z",
     "start_time": "2024-09-07T17:09:15.580859Z"
    }
   },
   "cell_type": "code",
   "source": "tourism_city_data.rename(index=rename_cities, inplace=True)",
   "id": "45dc154d277342a6",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:18.713186Z",
     "start_time": "2024-09-07T17:09:15.600266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for col in tourism_city_data.columns.tolist():\n",
    "    cleaned_df[col] = cleaned_df['df_city_location'].parallel_apply(\n",
    "        lambda city: tourism_city_data.loc[city, col]\n",
    "        if city in tourism_city_data.index else None\n",
    "    )"
   ],
   "id": "792ea32a11e0fd52",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:18.724746Z",
     "start_time": "2024-09-07T17:09:18.717323Z"
    }
   },
   "cell_type": "code",
   "source": "del tourism_city_data",
   "id": "9ece19418e60b9",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data about city welfare",
   "id": "988abacce5ef6735"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Happy about their city",
   "id": "ba93adb3a0ca12bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:18.850794Z",
     "start_time": "2024-09-07T17:09:18.727294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "happiness_citizens_to_live_in_city = pd.read_excel('data/city_data/Tavole-di-dati-QOL_23052024.xlsx',\n",
    "                                                   sheet_name=\"Tav. 1\",\n",
    "                                                   skiprows=2\n",
    "                                                   )\n",
    "happiness_citizens_to_live_in_city = happiness_citizens_to_live_in_city.iloc[:, 1:4]\n",
    "happiness_citizens_to_live_in_city.columns = happiness_citizens_to_live_in_city.columns.str.replace(' ', '_')\n"
   ],
   "id": "80091dbe6b5f21e5",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:18.865109Z",
     "start_time": "2024-09-07T17:09:18.853811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "happiness_citizens_to_live_in_city = happiness_citizens_to_live_in_city.replace(rename_cities)\n",
    "happiness_citizens_to_live_in_city.set_index(\"Città\", inplace=True)"
   ],
   "id": "90d423cb18a480fd",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:22.640106Z",
     "start_time": "2024-09-07T17:09:18.868619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cleaned_df['people_happy_of_the_city'] = cleaned_df['df_city_location'].parallel_apply(\n",
    "    lambda city: happiness_citizens_to_live_in_city.loc[city, 'Persone_soddisfatte_di_vivere_nella_propria_città'] \n",
    "    if city in happiness_citizens_to_live_in_city.index else None\n",
    ")"
   ],
   "id": "58ededd1ec50fd2",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:22.649179Z",
     "start_time": "2024-09-07T17:09:22.643183Z"
    }
   },
   "cell_type": "code",
   "source": "del happiness_citizens_to_live_in_city",
   "id": "68297530c030c7",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Perception of efficiency of public services",
   "id": "7cabe042a23a0c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:22.788451Z",
     "start_time": "2024-09-07T17:09:22.652124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "public_services_perception = pd.read_excel('data/city_data/Tavole-di-dati-QOL_23052024.xlsx',\n",
    "                                                   sheet_name=\"Tav. 3\",\n",
    "                                                   skiprows=2\n",
    "                                                   )\n",
    "public_services_perception.columns = public_services_perception.columns.str.replace(' ', '_')\n",
    "public_services_perception = public_services_perception.iloc[:, 1:-1]\n",
    "public_services_perception = public_services_perception.replace(rename_cities)\n",
    "public_services_perception.set_index(\"Città\", inplace=True)"
   ],
   "id": "a31d5e3168674e0d",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:54.112565Z",
     "start_time": "2024-09-07T17:09:22.791110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for col in public_services_perception.columns.tolist()[1:]:\n",
    "    cleaned_df[col] = cleaned_df['df_city_location'].parallel_apply(\n",
    "    lambda city: public_services_perception.loc[city, col] \n",
    "    if city in public_services_perception.index else None\n",
    ")"
   ],
   "id": "906ac8f1438c262b",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:54.123300Z",
     "start_time": "2024-09-07T17:09:54.115989Z"
    }
   },
   "cell_type": "code",
   "source": "del public_services_perception",
   "id": "5193739b04e2742d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Air quality and sound satisfaction",
   "id": "27e3f0a2fd175a73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:09:54.248131Z",
     "start_time": "2024-09-07T17:09:54.127136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "air_sound_quality = pd.read_excel('data/city_data/Tavole-di-dati-QOL_23052024.xlsx',\n",
    "                                           sheet_name=\"Tav. 4\",\n",
    "                                           skiprows=2\n",
    "                                           )\n",
    "air_sound_quality.columns = air_sound_quality.columns.str.replace(' ', '_')\n",
    "air_sound_quality = air_sound_quality.replace(rename_cities)\n",
    "air_sound_quality.set_index(\"Città\", inplace=True)"
   ],
   "id": "5bcf59c63709434b",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:10:01.981049Z",
     "start_time": "2024-09-07T17:09:54.250653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for col in air_sound_quality.columns.tolist()[1:]:\n",
    "    cleaned_df[col] = cleaned_df['df_city_location'].parallel_apply(\n",
    "        lambda city: air_sound_quality.loc[city, col]\n",
    "        if city in air_sound_quality.index else None\n",
    "    )"
   ],
   "id": "2ed2c7d516f4ffa3",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:10:01.992264Z",
     "start_time": "2024-09-07T17:10:01.985047Z"
    }
   },
   "cell_type": "code",
   "source": "del air_sound_quality",
   "id": "415c4878e6eb2ab5",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Transportation rails",
   "id": "809829e2a7ea8d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:10:02.124662Z",
     "start_time": "2024-09-07T17:10:01.997539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transport_rails = pd.read_excel('data/city_data/Tavole-di-dati-QOL_23052024.xlsx',\n",
    "                                  sheet_name=\"Tav. 5\",\n",
    "                                  skiprows=2\n",
    "                                  )\n",
    "transport_rails.columns = transport_rails.columns.str.replace(' ', '_')\n",
    "transport_rails = transport_rails.replace(rename_cities)\n",
    "transport_rails.set_index(\"Città\", inplace=True)\n",
    "transport_rails.rename(columns={\"Trasporto_pubblico_urbano_(autobus,_tram_o_metropolitana)\": \"Trasporto_pubblico\"}, inplace=True)\n"
   ],
   "id": "9b5e8be989c5086b",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:10:27.951402Z",
     "start_time": "2024-09-07T17:10:02.127647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for col in transport_rails.columns.tolist()[1:]:\n",
    "    cleaned_df[col] = cleaned_df['df_city_location'].parallel_apply(\n",
    "        lambda city: transport_rails.loc[city, col]\n",
    "        if city in transport_rails.index else None\n",
    "    )"
   ],
   "id": "74c823ec71af58d3",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:10:27.961615Z",
     "start_time": "2024-09-07T17:10:27.955132Z"
    }
   },
   "cell_type": "code",
   "source": "del transport_rails",
   "id": "678a985e9d991412",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### City is a good place to live for minorities",
   "id": "ff2e2eff47db7bbf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:10:28.092739Z",
     "start_time": "2024-09-07T17:10:27.965036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "minorities_fitness = pd.read_excel('data/city_data/Tavole-di-dati-QOL_23052024.xlsx',\n",
    "                                sheet_name=\"Tav. 11\",\n",
    "                                skiprows=2\n",
    "                                )\n",
    "minorities_fitness.columns = minorities_fitness.columns.str.replace(' ', '_')\n",
    "minorities_fitness = minorities_fitness.replace(rename_cities)\n",
    "minorities_fitness.set_index(\"Città\", inplace=True)"
   ],
   "id": "705644c259a4c7f4",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:10:51.203086Z",
     "start_time": "2024-09-07T17:10:28.094961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for col in minorities_fitness.columns.tolist()[1:]:\n",
    "    cleaned_df[col] = cleaned_df['df_city_location'].parallel_apply(\n",
    "        lambda city: minorities_fitness.loc[city, col]\n",
    "        if city in minorities_fitness.index else None\n",
    "    )"
   ],
   "id": "bdae3dbc961d74a3",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:10:51.214507Z",
     "start_time": "2024-09-07T17:10:51.207192Z"
    }
   },
   "cell_type": "code",
   "source": "del minorities_fitness",
   "id": "7e185532e521d9d2",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Night safety perception",
   "id": "94c6bb6b4883f584"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:10:51.344045Z",
     "start_time": "2024-09-07T17:10:51.218092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "night_safety = pd.read_excel('data/city_data/Tavole-di-dati-QOL_23052024.xlsx',\n",
    "                                   sheet_name=\"Tav. 12\",\n",
    "                                   skiprows=2\n",
    "                                   )\n",
    "night_safety.columns = night_safety.columns.str.replace(' ', '_')\n",
    "night_safety = night_safety.replace(rename_cities)\n",
    "night_safety.set_index(\"Città\", inplace=True)\n",
    "night_safety = night_safety.iloc[:, 1:3]"
   ],
   "id": "1778148b5323db63",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:10:54.880215Z",
     "start_time": "2024-09-07T17:10:51.346712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for col in night_safety.columns.tolist()[1:]:\n",
    "    cleaned_df[col] = cleaned_df['df_city_location'].parallel_apply(\n",
    "        lambda city: night_safety.loc[city, col]\n",
    "        if city in night_safety.index else None\n",
    "    )"
   ],
   "id": "4576f22a3ef2342b",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:10:54.897338Z",
     "start_time": "2024-09-07T17:10:54.891768Z"
    }
   },
   "cell_type": "code",
   "source": "del night_safety",
   "id": "8247c3b322ba0bc7",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:10:54.921068Z",
     "start_time": "2024-09-07T17:10:54.900036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from src.class_transformers import ColumnDropperTransformer, IntoBinaryTransformer, CoordinatesTransformer\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(transform_output=\"pandas\")\n",
    "pd.options.display.float_format = \"{:.0f}\".format\n"
   ],
   "id": "e258d1232ce2730d",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:11:05.567750Z",
     "start_time": "2024-09-07T17:10:54.923726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = cleaned_df.copy()\n",
    "\n",
    "# Columns to drop because of high correlation\n",
    "to_drop_corr = [\n",
    "    \"host_acceptance_rate\",\n",
    "    \"host_total_listings_count\",\n",
    "    \"bathrooms\",\n",
    "    \"bedrooms\",\n",
    "    \"beds\",\n",
    "    \"review_scores_accuracy\",\n",
    "    \"review_scores_cleanliness\",\n",
    "    \"review_scores_checkin\",\n",
    "    \"review_scores_communication\",\n",
    "    \"review_scores_location\",\n",
    "    \"review_scores_value\",\n",
    "    \"amenities\"\n",
    "]\n",
    "\n",
    "widely_unbalanced_features = [\n",
    "    \"host_has_profile_pic\",\n",
    "    \"host_identity_verified\",\n",
    "    \"email_verification\",\n",
    "    \"phone_verification\",\n",
    "    \"work_email_verification\",\n",
    "]\n",
    "\n",
    "eng_after_exploration_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"Drop columns\", ColumnDropperTransformer(columns=to_drop_corr)),\n",
    "        (\n",
    "            \"Drop unbalanced columns\",\n",
    "            ColumnDropperTransformer(columns=widely_unbalanced_features),\n",
    "        ),\n",
    "        (\n",
    "            \"Transform Response Rate\",\n",
    "            IntoBinaryTransformer(\n",
    "                feature=\"host_response_rate\", cat1=\"100\", cond=\"x==100\", cat2=\"lower\"\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"Transform Minimum Nights\",\n",
    "            IntoBinaryTransformer(\n",
    "                feature=\"minimum_nights\", cat1=\"1\", cond=\"x<=1\", cat2=\"more_than_1\"\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"Transform Maximum Nights\",\n",
    "            IntoBinaryTransformer(\n",
    "                feature=\"maximum_nights\",\n",
    "                cat1=\"less_than_100\",\n",
    "                cond=\"x<=100\",\n",
    "                cat2=\"more_than_100\",\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"Transform City Population\",\n",
    "            IntoBinaryTransformer(\n",
    "                feature=\"listing_city_pop\",\n",
    "                cat1=\"less_than_300k\",\n",
    "                cond=\"x<=300000\",\n",
    "                cat2=\"more_than_300k\",\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"Transform Review Score Rating\",\n",
    "            IntoBinaryTransformer(\n",
    "                feature=\"review_scores_rating\",\n",
    "                cat1=\"less_than_4.8\",\n",
    "                cond=\"x<4.8\",\n",
    "                cat2=\"more_than_4.8\",\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "        (\n",
    "            \"Transform Host Response Time\",\n",
    "            IntoBinaryTransformer(\n",
    "                feature=\"host_response_time\",\n",
    "                cat1=\"within_an_hour\",\n",
    "                cond=\"x=='within an hour'\",\n",
    "                cat2=\"more_than_one_hour\",\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"Transform Property Type\",\n",
    "            IntoBinaryTransformer(\n",
    "                feature=\"property_type\",\n",
    "                cat1=\"entire_property\",\n",
    "                cond=\"x=='entire_property'\",\n",
    "                cat2=\"other\",\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"Transform Room Type\",\n",
    "            IntoBinaryTransformer(\n",
    "                feature=\"room_type\",\n",
    "                cat1=\"entire_home\",\n",
    "                cond=\"x=='Entire home/apt'\",\n",
    "                cat2=\"other\",\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"Transform Bathrooms Text\",\n",
    "            IntoBinaryTransformer(\n",
    "                feature=\"bathrooms_text\",\n",
    "                cat1=\"single\",\n",
    "                cond=\"x=='single'\",\n",
    "                cat2=\"other\",\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"Coordinates to spatial\",\n",
    "            CoordinatesTransformer()\n",
    "        ),\n",
    "    ],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "df = eng_after_exploration_pipeline.fit_transform(df)"
   ],
   "id": "5274876b671cd488",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ..... (step 1 of 12) Processing Drop columns, total=   0.0s\n",
      "[Pipeline]  (step 2 of 12) Processing Drop unbalanced columns, total=   0.0s\n",
      "[Pipeline]  (step 3 of 12) Processing Transform Response Rate, total=   1.1s\n",
      "[Pipeline]  (step 4 of 12) Processing Transform Minimum Nights, total=   1.1s\n",
      "[Pipeline]  (step 5 of 12) Processing Transform Maximum Nights, total=   1.1s\n",
      "[Pipeline]  (step 6 of 12) Processing Transform City Population, total=   1.1s\n",
      "[Pipeline]  (step 7 of 12) Processing Transform Review Score Rating, total=   1.2s\n",
      "[Pipeline]  (step 8 of 12) Processing Transform Host Response Time, total=   1.2s\n",
      "[Pipeline]  (step 9 of 12) Processing Transform Property Type, total=   1.2s\n",
      "[Pipeline]  (step 10 of 12) Processing Transform Room Type, total=   1.2s\n",
      "[Pipeline]  (step 11 of 12) Processing Transform Bathrooms Text, total=   1.2s\n",
      "[Pipeline]  (step 12 of 12) Processing Coordinates to spatial, total=   0.1s\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ML pipeline",
   "id": "42b4f9401779adba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:11:05.759261Z",
     "start_time": "2024-09-07T17:11:05.571030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from feature_engine.datetime import DatetimeSubtraction\n",
    "from feature_engine.creation import RelativeFeatures\n",
    "from feature_engine.encoding import OneHotEncoder, CountFrequencyEncoder, OrdinalEncoder\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from feature_engine.imputation import MeanMedianImputer, CategoricalImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures, PowerTransformer, RobustScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sys\n",
    "from sklearn.neural_network import MLPRegressor\n"
   ],
   "id": "69cd556874c63416",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:11:05.771104Z",
     "start_time": "2024-09-07T17:11:05.762335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid={\n",
    "    \"regressor__n_estimators\": [400], #, 400, 800],\n",
    "    \"regressor__criterion\": [\"absolute_error\"],\n",
    "    \"regressor__random_state\": [874631],\n",
    "    \"regressor__verbose\": [True],\n",
    "    #\"regressor__min_impurity_decrease\": [0, 0.1, 0.2, 0.3],\n",
    "    \"regressor__bootstrap\": [True],\n",
    "    \"regressor__oob_score\": [True],\n",
    "}"
   ],
   "id": "5b0c4f60de86e836",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:11:06.004375Z",
     "start_time": "2024-09-07T17:11:05.775169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "review_dates_feature = [\"first_review\", \"last_review\"]\n",
    "\n",
    "ohe_feature = [\n",
    "    \"df_city_location\",\n",
    "    \"host_is_superhost\",\n",
    "    \"host_response_time\",\n",
    "    \"property_type\",\n",
    "    \"room_type\",\n",
    "    \"bathrooms_text\",\n",
    "    \"host_response_rate\",\n",
    "    \"minimum_nights\",\n",
    "    \"maximum_nights\",\n",
    "    \"listing_city_pop\",\n",
    "    \"review_scores_rating\",\n",
    "    'amenities_internet',\n",
    "    'amenities_self-checkin',\n",
    "    'amenities_host-greeting',\n",
    "    'amenities_pool',\n",
    "    'amenities_oven',\n",
    "    'amenities_microwave',\n",
    "    'amenities_garden',\n",
    "    'amenities_streaming',\n",
    "    'amenities_gym',\n",
    "    'amenities_elevator',\n",
    "    'amenities_heating',\n",
    "    \"amenities_air-conditioning\",\n",
    "    \"amenities_workspace\",\n",
    "    \"amenities_freezer\",\n",
    "    \"amenities_first-aid-kit\",\n",
    "    \"amenities_dishwasher\",\n",
    "    \"amenities_long-term-stays\",\n",
    "    \"amenities_pets-allowed\",\n",
    "    \"amenities_bathtube\",\n",
    "    \"amenities_bbq-grill\",\n",
    "    \"amenities_lake-bay-view\",\n",
    "]\n",
    "\n",
    "ohe_most_frequent = [\"listing_city\", \"neighbourhood_cleansed\"]\n",
    "\n",
    "host_id_feature = [\"host_id\"]\n",
    "\n",
    "host_since_feature = [\"host_since\"]\n",
    "\n",
    "numerical_feature = [\n",
    "    \"host_listings_count\",\n",
    "    \"host_location\",\n",
    "    \"number_of_reviews\",\n",
    "    \"reviews_per_month\",\n",
    "    \"accommodates\",\n",
    "    \"Total_nights_spent_in_tourist_accommodation_establishments\",\n",
    "    'Nights_spent_in_tourist_accommodation_establishments_by_residents',\n",
    "    'Nights_spent_in_tourist_accommodation_establishments_by_non-residents',\n",
    "    'Total_nights_spent_in_tourist_accommodation_establishments_per_resident_population',\n",
    "    'people_happy_of_the_city',\n",
    "    'Indice_sintetico_sulla_percezione_dell’efficienza_dei_servizi_pubblici_della_città',\n",
    "    'Persone_soddisfatte_dei_trasporti_pubblici',\n",
    "    'Persone_soddisfatte_degli_spazi_verdi',\n",
    "    'Persone_soddisfatte_delle_infrastrutture_sportive',\n",
    "    'Persone_soddisfatte_delle_infrastrutture_culturali',\n",
    "    'Persone_soddisfatte_delle_scuole_e_degli_altri_servizi_di_formazione',\n",
    "    'Persone_soddisfatte_di_servizi_sanitari,_medici_e_ospedali',\n",
    "    'Persone_soddisfatte_degli_spazi_pubblici',\n",
    "    \"Persone_soddisfatte_della_qualità_dell'aria\",\n",
    "    'Persone_soddisfatte_del_livello_di_rumore',\n",
    "    'Automobile',\n",
    "    'Motocicletta',\n",
    "    'Bicicletta',\n",
    "    'A_piedi',\n",
    "    'Treno',\n",
    "    'Trasporto_pubblico',\n",
    "    'La_città_è_un_buon_posto_in_cui_vivere_per_le_persone_in_generale',\n",
    "    'La_città_è_un_buon_posto_in_cui_vivere_per_le_minoranze_etniche',\n",
    "    'La_città_è_un_buon_posto_in_cui_vivere_per_le_persone_omosessuali',\n",
    "    'La_città_è_un_buon_posto_in_cui_vivere_per_gli_immigrati_provenienti_da_altri_paesi',\n",
    "    'La_città_è_un_buon_posto_in_cui_vivere_per_le_famiglie_con_bambini_piccoli',\n",
    "    'La_città_è_un_buon_posto_in_cui_vivere_per_le_persone_anziane',\n",
    "    'Persone_che_si_sentono_sicure_a_camminare_da_sole_di_notte_nella_propria_città'\n",
    "] #+ description_features\n",
    "\n",
    "coordinates_feature = [\n",
    "    \"x_coord\",\n",
    "    \"y_coord\",\n",
    "    \"z_coord\"\n",
    "]\n",
    "\n",
    "# Drop rows with NaN in target\n",
    "df = df.loc[df[\"price\"].notnull(), :]\n",
    "\n",
    "X = df.drop([\"price\"], axis=1, inplace=False)\n",
    "y = df[\"price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=874631\n",
    ")\n",
    "\n",
    "# Drop the rows from the train set with outliers in price\n",
    "#mask = y_train <= 10000\n",
    "#X_train: np.array = X_train[mask]\n",
    "#y_train: np.array = y_train[mask]\n",
    "\n",
    "wizard_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"ScrapingDate-add\",\n",
    "            ScrapingDateTransformer()\n",
    "        ),\n",
    "        # Review Dates (RD)\n",
    "        (\n",
    "            \"RD_engineering\",\n",
    "            DatetimeSubtraction(\n",
    "                variables=\"last_review\",\n",
    "                reference=\"first_review\",\n",
    "                output_unit=\"D\",\n",
    "                drop_original=False,\n",
    "                new_variables_names=[\"days_active_reviews\"],\n",
    "                missing_values=\"ignore\",\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"RD_imputation\",\n",
    "            MeanMedianImputer(\n",
    "                imputation_method=\"median\", variables=[\"days_active_reviews\"]\n",
    "            ),\n",
    "        ),\n",
    "        # ========================\n",
    "        # One-hot-encoding (OHE)\n",
    "        (\n",
    "            \"OHE_imputation\",\n",
    "            CategoricalImputer(\n",
    "                imputation_method=\"frequent\",\n",
    "                variables=ohe_feature,\n",
    "                return_object=True,\n",
    "                ignore_format=False,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"OHE_encoding\",\n",
    "            OneHotEncoder(\n",
    "                top_categories=None,\n",
    "                drop_last=True,\n",
    "                drop_last_binary=True,\n",
    "                ignore_format=False,\n",
    "                variables=ohe_feature,\n",
    "            ),\n",
    "        ),\n",
    "        # ========================\n",
    "        # One-hot-encoding Top Frequent (OHETF)\n",
    "        (\n",
    "            \"OHETF_imputation\",\n",
    "            CategoricalImputer(\n",
    "                imputation_method=\"frequent\",\n",
    "                variables=ohe_most_frequent,\n",
    "                return_object=True,\n",
    "                ignore_format=False,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"OHETF_encoding\",\n",
    "            OneHotEncoder(\n",
    "                top_categories=30,\n",
    "                drop_last=True,\n",
    "                drop_last_binary=True,\n",
    "                ignore_format=False,\n",
    "                variables=ohe_most_frequent,\n",
    "            ),\n",
    "        ),\n",
    "        # =======================\n",
    "        # Host ID (HID)\n",
    "        (\n",
    "            \"HID_imputation\",\n",
    "            CategoricalImputer(\n",
    "                imputation_method=\"missing\",\n",
    "                variables=host_id_feature,\n",
    "                fill_value=\"MISSING\",\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"HID_encoding\",\n",
    "            CountFrequencyEncoder(\n",
    "                encoding_method=\"count\", missing_values=\"ignore\", unseen=\"encode\"\n",
    "            ),\n",
    "        ),\n",
    "        # =========================\n",
    "        # Host since (HS)\n",
    "        (\n",
    "            \"HS_engineering\",\n",
    "            DatetimeSubtraction(\n",
    "                variables=[\"scraping_date\"],\n",
    "                reference=[\"host_since\"],\n",
    "                output_unit=\"D\",\n",
    "                drop_original=False,\n",
    "                new_variables_names=[\"host_since_days\"],\n",
    "                missing_values=\"ignore\",\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"HS_imputation\",\n",
    "            MeanMedianImputer(\n",
    "                imputation_method=\"median\", variables=[\"host_since_days\"]\n",
    "            ),\n",
    "        ),\n",
    "        # ==========================\n",
    "        # Numerical features (NF)\n",
    "        (\n",
    "            \"NF_imputation\",\n",
    "            SklearnTransformerWrapper(\n",
    "                transformer=KNNImputer(n_neighbors=5, weights=\"uniform\"),\n",
    "                variables=numerical_feature,\n",
    "            ),\n",
    "        ),\n",
    "        # ============================\n",
    "        # Coordinates numerical (COO)\n",
    "        (\n",
    "            \"COO_imputation\",\n",
    "            MeanMedianImputer(\n",
    "                imputation_method=\"median\", variables=coordinates_feature\n",
    "            ),\n",
    "        ),\n",
    "        # ========================\n",
    "        # Drop features not needed\n",
    "        # ========================\n",
    "        (\n",
    "            \"ColumnDropperTransformer\",\n",
    "            ColumnDropperTransformer(\n",
    "                columns=[\n",
    "                    \"last_review\",\n",
    "                    \"first_review\",\n",
    "                    \"scraping_date\",\n",
    "                    \"host_since\",\n",
    "                ]\n",
    "            )\n",
    "        ),\n",
    "        # =======================\n",
    "        # Scaling\n",
    "        # ======================================================================\n",
    "        #(\n",
    "        #    \"PowerTransformer\",\n",
    "        #    SklearnTransformerWrapper(\n",
    "        #        transformer=PowerTransformer(\n",
    "        #            method=\"yeo-johnson\",\n",
    "        #            standardize=True,\n",
    "        #            copy=False\n",
    "        #        ),\n",
    "        #        variables=[\n",
    "        #                      \"days_active_reviews\",\n",
    "        #                      \"host_since_days\",\n",
    "        #                  ]\n",
    "        #                  + numerical_feature\n",
    "        #    )\n",
    "        #),\n",
    "        ( \n",
    "            \"MinMaxScaling\",\n",
    "            SklearnTransformerWrapper(\n",
    "                transformer=MinMaxScaler(),\n",
    "                variables=coordinates_feature + numerical_feature + [\"days_active_reviews\", \"host_since_days\"]\n",
    "            ),\n",
    "        ),\n",
    "        # ============\n",
    "        # Prediction\n",
    "        # ============\n",
    "        #(\n",
    "        #    \"TransformedTarget-RandomForestRegressor\",\n",
    "        #    TransformedTargetRegressor(regressor=RandomForestRegressor(\n",
    "        #        n_estimators=100,\n",
    "        #        criterion=\"squared_error\",\n",
    "        #        bootstrap=True,\n",
    "        #        max_samples=0.7,\n",
    "        #        oob_score=True,\n",
    "        #        n_jobs=-1,\n",
    "        #        random_state=874631,\n",
    "        #    ),\n",
    "        #        transformer=PowerTransformer(\n",
    "        #            method=\"yeo-johnson\",\n",
    "        #            standardize=True,\n",
    "        #            copy=False\n",
    "        #        ),\n",
    "        #    )\n",
    "        #),\n",
    "        (\n",
    "            \"RFR\",\n",
    "            GridSearchCV(\n",
    "                estimator=TransformedTargetRegressor(\n",
    "                    regressor=RandomForestRegressor(),\n",
    "                    transformer=PowerTransformer(\n",
    "                        method=\"yeo-johnson\",\n",
    "                        standardize=True,\n",
    "                        copy=False,\n",
    "                    )\n",
    "                ),\n",
    "                param_grid=param_grid,\n",
    "                cv=5,\n",
    "                n_jobs=-1,\n",
    "                verbose=True,\n",
    "                scoring=[\"neg_mean_absolute_error\", \"neg_mean_squared_error\", \"r2\"],\n",
    "                refit=\"r2\",\n",
    "                error_score=\"raise\",\n",
    "            ),\n",
    "        ),\n",
    "        #(\n",
    "        #    \"MLPRegressor\",\n",
    "        #    MLPRegressor(hidden_layer_sizes=(100, 100, 100),\n",
    "        #                 activation=\"relu\",\n",
    "        #                 solver=\"adam\",\n",
    "        #                 alpha=0.01,\n",
    "        #                 batch_size=500,\n",
    "        #                 learning_rate=\"constant\",\n",
    "        #                 learning_rate_init=0.001,\n",
    "        #                 max_iter=200,\n",
    "        #                 shuffle=True,\n",
    "        #                 random_state=874631,\n",
    "        #                 tol=1e-4,\n",
    "        #                 verbose=True,\n",
    "        #                 warm_start=True,\n",
    "        #                 momentum=0.9,\n",
    "        #                 early_stopping=False,\n",
    "        #                 validation_fraction=0.1,\n",
    "        #                 n_iter_no_change=20\n",
    "        #    )\n",
    "        #),\n",
    "    ],\n",
    "    verbose=True,\n",
    ")\n"
   ],
   "id": "a34d8d215a1d3570",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:11:06.111964Z",
     "start_time": "2024-09-07T17:11:06.007987Z"
    }
   },
   "cell_type": "code",
   "source": "test = X_train.copy()",
   "id": "90ae10e6d7a680f5",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T17:11:06.834835Z",
     "start_time": "2024-09-07T17:11:06.114473Z"
    }
   },
   "cell_type": "code",
   "source": "#test = wizard_pipe.fit_transform(test)",
   "id": "8dab90eb55590f4a",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "This 'Pipeline' has no attribute 'fit_transform'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[42], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m test \u001B[38;5;241m=\u001B[39m \u001B[43mwizard_pipe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m(test)\n",
      "File \u001B[0;32m~/repositories/price-forecast/venv/lib/python3.10/site-packages/sklearn/utils/_available_if.py:40\u001B[0m, in \u001B[0;36m_AvailableIfDescriptor.__get__\u001B[0;34m(self, obj, owner)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__get__\u001B[39m(\u001B[38;5;28mself\u001B[39m, obj, owner\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     38\u001B[0m         \u001B[38;5;66;03m# delegate only on instances, not the classes.\u001B[39;00m\n\u001B[1;32m     39\u001B[0m         \u001B[38;5;66;03m# this is to allow access to the docstrings.\u001B[39;00m\n\u001B[0;32m---> 40\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mowner\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mowner\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m         out \u001B[38;5;241m=\u001B[39m MethodType(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfn, obj)\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     44\u001B[0m         \u001B[38;5;66;03m# This makes it possible to use the decorated method as an unbound method,\u001B[39;00m\n\u001B[1;32m     45\u001B[0m         \u001B[38;5;66;03m# for instance when monkeypatching.\u001B[39;00m\n",
      "File \u001B[0;32m~/repositories/price-forecast/venv/lib/python3.10/site-packages/sklearn/utils/_available_if.py:34\u001B[0m, in \u001B[0;36m_AvailableIfDescriptor._check\u001B[0;34m(self, obj, owner)\u001B[0m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(attr_err_msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m check_result:\n\u001B[0;32m---> 34\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(attr_err_msg)\n",
      "\u001B[0;31mAttributeError\u001B[0m: This 'Pipeline' has no attribute 'fit_transform'"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#test.head(100)",
   "id": "456aa6cf51ef53ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-09-07T17:11:39.206101Z"
    }
   },
   "cell_type": "code",
   "source": "fitting_model = wizard_pipe.fit(X_train, y_train)",
   "id": "46022af877ee43e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] . (step 1 of 16) Processing ScrapingDate-add, total=   0.1s\n",
      "[Pipeline] ... (step 2 of 16) Processing RD_engineering, total=   0.2s\n",
      "[Pipeline] .... (step 3 of 16) Processing RD_imputation, total=   0.1s\n",
      "[Pipeline] ... (step 4 of 16) Processing OHE_imputation, total=   0.6s\n",
      "[Pipeline] ..... (step 5 of 16) Processing OHE_encoding, total=   2.5s\n",
      "[Pipeline] . (step 6 of 16) Processing OHETF_imputation, total=   0.1s\n",
      "[Pipeline] ... (step 7 of 16) Processing OHETF_encoding, total=   2.3s\n",
      "[Pipeline] ... (step 8 of 16) Processing HID_imputation, total=   0.2s\n",
      "[Pipeline] ..... (step 9 of 16) Processing HID_encoding, total=   0.2s\n",
      "[Pipeline] .. (step 10 of 16) Processing HS_engineering, total=   0.2s\n",
      "[Pipeline] ... (step 11 of 16) Processing HS_imputation, total=   0.1s\n",
      "[Pipeline] ... (step 12 of 16) Processing NF_imputation, total=  27.9s\n",
      "[Pipeline] .. (step 13 of 16) Processing COO_imputation, total=   0.2s\n",
      "[Pipeline]  (step 14 of 16) Processing ColumnDropperTransformer, total=   0.0s\n",
      "[Pipeline] ... (step 15 of 16) Processing MinMaxScaling, total=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filippo/repositories/price-forecast/venv/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but PowerTransformer was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/filippo/repositories/price-forecast/venv/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but PowerTransformer was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/filippo/repositories/price-forecast/venv/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but PowerTransformer was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/filippo/repositories/price-forecast/venv/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but PowerTransformer was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/filippo/repositories/price-forecast/venv/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but PowerTransformer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "pred = wizard_pipe.predict(X_test)\n",
    "print(\n",
    "    f\"\\nExplained variance score is {explained_variance_score(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Absolute Error is {mean_absolute_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Squared Error is {mean_squared_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nR^2 Error is {r2_score(y_true=y_test, y_pred=pred)}\",\n",
    ")\n"
   ],
   "id": "a34bd2dfb1933a6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#plot_loss = pd.DataFrame(wizard_pipe[\"MLPRegressor\"].loss_curve_, columns=[\"loss\"])",
   "id": "e82b01f8512f252e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#fig = px.line(plot_loss, x = plot_loss.index, y = \"loss\")\n",
    "#fig.show()"
   ],
   "id": "e929f316f17ea1d1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
